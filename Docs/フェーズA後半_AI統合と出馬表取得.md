# AI結合アーキテクチャへの移行（フェーズA後半）と出馬表取得計画

ユーザーの指摘の通り、現在の実装（プログラム依存のスコアリング）は確証ある「事実」を計算する上では非常に強力ですが、「どの条件を評価根拠とするか（意味づけ）」「どのように総合評価を下すか（スコアリング）」という**本来AI（LLM）が担うべき解釈プロセス**までプログラムで行ってしまっています。

このため、算出結果が「AIの分析」ではなく「単なる数式」で終わっており、また対象となる「本番の出走メンバー情報（今年の出馬表）」も未取得でした。

これを是正し、「真のAIフェーズ」に移行するための計画を以下にまとめます。

---

## 1. AIへの役割の「分離と移管」方針

### 現状のアプローチ（脱却対象）
1. RAG（データベース）から事実を引っ張る。
2. Pythonプログラムが全件探索して「出現率」を計算する。
3. **Pythonプログラムが「母数と中央値を掛け算」してスコアをつける。**（← これがおかしい）
4. UIに偽物の「AI見解」を連結して表示する。（← これが偽物）

### 新しいアプローチ（フェーズA後半仕様）
1. RAGから事実を引っ張る。（プログラムの役目：完了済）
2. Pythonプログラムが全件探索して「条件ごとの３着内率・中央値」という**事実レポート（JSON等）**を生成する。（プログラムの役目：完了済）
3. **【変更箇所1】 出馬表の取得**：今年の出走馬リストをWebから取得し、対象の馬をエンジンに流し込む。出走馬に対する「該当条件」のリストを事実レポートに追加する。
4. **【変更箇所2】 AIの推論・解釈**：事実レポート（各馬がどのような有用条件に合致しているかの一覧）をLLM API（OpenAI / Gemini等）に投げる。
5. **AI（LLM）自身の役目**:
   - 与えられた条件のうち、「先行 × 前走G1」といった因果関係が強いものを重視し、「枠 × 生産牧場」のような薄いものを切り捨てる。
   - 重視した根拠を元に全馬を比較ランキングし、0〜100点等で自らスコアリングする。
   - ランキングの根拠を、指定された事実数字（N/M頭、○%）だけを用いて日本語で出力する。
6. UIにはAIが返した**本物の回答**をプロットする。

---

## 2. 実装タスク（明日以降の計画）

### タスク 23: 本番出馬表（未結果レース）の動的取得
*   **出馬表スクレイパー (`src/scripts/scrape_race_card.py` 相当)**: Netkeibaの今週のレース情報（出馬表ページ）へアクセスし、馬ID・名称・枠・斤量・騎手・現在オッズ等を取得する。
*   **データの合成**: 取得した出馬表データを元に、DBから既存の血統・過去成績を結合し、予測の入力配列（`entries`）を作成する。

### タスク 24: AI（LLM）とのAPI統合レイヤーの構築
*   **プロンプトジェネレータ**: `validator.py` を通過したクリーンな事実データ（採用条件リストと出走馬ごとの該当マッピング）を受け取り、「あなたは競馬予想AIです。提供された計算事実だけを用いて各馬を評価してください」というシステムプロンプトを構築する。
*   **スコアリングの廃絶**: `inference.py` 上の決定論的な `score_entries` ロジックを廃止するか、あるいはLLMに「参考事実」として渡す程度のリファレンス指標へと降格させる。
*   **AI推論実行**: APIを通じてAIへリクエストを投げ、評価理由スコアなどを構造化JSON形式（Function Calling / Structured Outputs）で受け取る。

### タスク 25: 対話型チャットへの昇華
*   現在一方通行のチャットUIを改修し、本物のAIが文脈を記憶しながら、「じゃあ、人気薄だけで考えるとどうなる？」「1枠が不利なのはなぜ？」といったフォローアップの問いに答えられるようにする。

---

## 3. 次のステップ（ユーザー承認後）
明日、上記の「本番出馬表の取得スクレイパーの実装」から開始し、順次APIサーバー側のLLM統合ロジックへの改修へと進みます。
